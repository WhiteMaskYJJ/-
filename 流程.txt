神经网络实现逻辑回归

注：
***表示封装成函数
**表示全局变量

一、数据获取
X（n,m），Y(m,1)
有m组数据，n种变量

二、参数初始化
1.偏移量b(1，1)**
2.权重W（n,1）**
3.误差值(多组数据平均值)  j=0 **
4.预测值A (每组数据存在一个预测值) Z（m,1） ***传入X根据W和b的到预测值
5.迭代次数
6.learn_rate学习率

三、实现sigmoid函数将预测值Z，映射到0-1区间 *** 传入预测值得到映射



四、实现求dz的函数(方便后续找参数b和w的梯度db，dw)***
dz=A-Y
shape=[1,m]

五、根据dz求解db（由于存在多组数据需要取所有数组的平均梯度）***
dw= (1/m) * np.dot(X,dz.T)
db= (1/m) * np.sum(dz)

开始封装***
传入参数train_X ，train_Y
for(迭代次数)循环
每一次
调用函数得到Z ---> 映射值A ---> 梯度dz -->参数梯度dw,db
跟新参数W,b
W=W-learn_rate*dw
b=b-learn_rate*db
